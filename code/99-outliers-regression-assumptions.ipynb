{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec79c3c-8dff-4d0f-8cff-2606d3dc747c",
   "metadata": {},
   "source": [
    "### 1. Section on outlier removal \n",
    "- created this section after finding non-normal errors\n",
    "- but the errors really aren't too far from normal\n",
    "- and also even after removing outliers the Shapiro-Wilk test failed\n",
    "\n",
    "In this example, we used the Isolation Forest to detect outliers and marked them in the DataFrame using an additional column called 'outlier'. The contamination parameter determines the proportion of outliers expected in the data (typically set between 0 and 0.5). You can adjust this parameter based on your domain knowledge or perform cross-validation to find an optimal value.\n",
    "\n",
    "After outlier detection, you can further analyze the 'outlier' column to investigate the outliers and decide whether to remove them from the dataset. Keep in mind that outlier removal should be done judiciously, considering the context and domain knowledge, and it may depend on the size and nature of your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e552977-5dbb-4b23-bedd-f038638fe45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Combine the target and predictor columns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_log, X], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m contamination \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform outlier detection using Isolation Forest\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Combine the target and predictor columns\n",
    "all_data = pd.concat([y_log, X], axis=1)\n",
    "contamination = 0.05\n",
    "# Perform outlier detection using Isolation Forest\n",
    "outlier_detector = IsolationForest(contamination=contamination)\n",
    "outliers = outlier_detector.fit_predict(all_data)\n",
    "# Add an 'outlier' column to mark the outliers\n",
    "all_data['outlier'] = np.where(outliers == -1, True, False)\n",
    "# Reprot number of outliers\n",
    "all_data['outlier'].sum()\n",
    "\n",
    "# Separate the cleaned data and target variable\n",
    "X_clean = all_data.drop(columns=['outlier', y_log.name])\n",
    "y_log_clean = all_data[y_log.name]\n",
    "\n",
    "# Remove rows with outliers from the data\n",
    "X_clean = X_clean[~all_data['outlier']].copy()\n",
    "y_log_clean = y_log_clean[~all_data['outlier']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8ceda4-70cf-4c9c-a1e8-05134ab8beb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Separate the cleaned data and target variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_clean \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier\u001b[39m\u001b[38;5;124m'\u001b[39m, y_log\u001b[38;5;241m.\u001b[39mname])\n\u001b[0;32m      3\u001b[0m y_log_clean \u001b[38;5;241m=\u001b[39m all_data[y_log\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Remove rows with outliers from the data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e14ea9-2425-42b6-b289-188887579c64",
   "metadata": {},
   "source": [
    "#### Retrain model after performing outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9b1b1-e54b-4bf8-9e19-bc43b8f92e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrain on clean data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_log_clean, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=4)\n",
    "\n",
    "# Add a constant column to the predictor variables dataframe\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Add the constant to the test set as well so we can use the model to form predictions on the test set later\n",
    "X_test = sm.add_constant(X_test)\n",
    "X_test.head()\n",
    "\n",
    "# Fit the multivariate regression model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "trained_model = model.fit()\n",
    "\n",
    "# to calculate residuals and R-squared for the test set, we'll need to get the model predictions first\n",
    "y_pred_test = trained_model.predict(X_test)\n",
    "\n",
    "# calculate residuals \n",
    "test_residuals = y_pred_test - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49329f40-40e9-4aaf-9684-efe7ab466138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import assess_normal_resid \n",
    "\n",
    "assess_normal_resid(trained_model, test_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8f8bf-abf5-4b6b-8a37-58ddc31ebeae",
   "metadata": {},
   "source": [
    "### 2. Section on comparing real data QQ-plot to simulated data QQ-plot; decided this section probably isn't worth the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867ea16-6562-4de4-84c5-42ecf58533e7",
   "metadata": {},
   "source": [
    "What happens if we decrease the sample size of our simulation? Let's try to generate a QQ-plot containing only 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30bc5b-71e8-417d-bd5b-0689a3938da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # set seed for reproducibility\n",
    "normal_data = np.random.normal(loc=0, scale=1, size=200) # mean of 0, std of 1, len(samples) = number of observations used to train/fit model\n",
    "normal_data.shape\n",
    "\n",
    "## create qq-plot\n",
    "import statsmodels.api as sm\n",
    "sm.qqplot(normal_data, line='s');\n",
    "\n",
    "# Shapiro-Wilk test for normality\n",
    "shapiro_stat, shapiro_p = stats.shapiro(normal_data)\n",
    "print(f\"Shapiro-Wilk test: statistic={shapiro_stat:.4f}, p-value={shapiro_p:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bf486-9c70-4c83-9c54-083bb4fe6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notice how the SW test nearly fails even though this data comes from a normal distrition. Testing normality can be a difficult task when data is very limited. What happens if we decrease the sample size of our simulation? Let's try to generate a QQ-plot containing the same number of samples used to train our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
