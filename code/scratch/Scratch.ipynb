{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad94b4c-624c-4fd3-9df0-ad7af34e3e9b",
   "metadata": {},
   "source": [
    "### things to fit in...\n",
    "* why multivariate regression: mediating variables\n",
    "\n",
    "### Flow1\n",
    "\n",
    "1a. Univariate predictive regression (Regression goals, univariate regression for predictive modeling); pre-filled notebook\n",
    "    * frame modeling goals\n",
    "    * review some regression (must draw line; sometimes transform data) and modeling basics (under/overfitting, evaluating model)\n",
    "    * show that univariate models are somewhat limited even for simply predictive purposes\n",
    "    * end with exploring the single most predictive predictor variable\n",
    "    \n",
    "1b. Explaining regression models\n",
    "    * assumptions\n",
    "    * accounting for multiple comparisons\n",
    "    \n",
    "2. Multivariate regression (benefit of multiple predictors /mediating effects, evaluating bias vs variance in-depth) \n",
    "    * flaws of univariate modeling approaches, benefits of multiple predictors, talk about mediating effects (corr != causation) -> both improves predictive accuracy and yields more truthful models\n",
    "    * example using three of the most predictive variables\n",
    "    * example that illustrates importants of standardization\n",
    "    * example that illustrates issue of multicollinearity\n",
    "    * try ALL predictors - what happens? Evaluating bias vs variance \n",
    "\n",
    "3. Regularization, feature selection, etc.\n",
    "\n",
    "4. Assumptions of regression and regression stats (the hard stuff!)\n",
    "\n",
    "3. Explanatory multivariate regression. Iterate between predict and explain goals when covering various appraoches: lasso, ridge\n",
    "\n",
    "\n",
    "### Flow2\n",
    "\n",
    "1. Predictive univariate regression \n",
    "    * frame modeling goals\n",
    "    * review some regression (must draw line; sometimes transform data) and modeling basics (under/overfitting, evaluating model)\n",
    "    * show that univariate models are somewhat limited even for simply predictive purposes\n",
    "    * end with exploring the most predictive predictor variable\n",
    "    \n",
    "2. Predictive multivariate regression\n",
    "    * show benefit of multiple predictors and talk about mediating effects\n",
    "    * try ALL predictors - what happens? Evaluating bias vs variance \n",
    "\n",
    "3. Regularization, feature selection, etc.\n",
    "\n",
    "4. Assumptions of regression and regression stats (the hard stuff!)\n",
    "\n",
    "3. Explanatory multivariate regression. Iterate between predict and explain goals when covering various appraoches: lasso, ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd373c47-b3b1-414e-81be-ecaeb5a8502b",
   "metadata": {},
   "source": [
    "##### Univariate linear regression\n",
    "As a reminder, the classic equation for a univariate linear regression model is shown below.\n",
    "\n",
    "$$y = mx + b$$\n",
    "\n",
    "where...\n",
    "\n",
    "* $y$ = observed values of the target variable / dependent variable / response variable\n",
    "* $x$ = observed values of the predictor variable / model feature / independent variable / explanatory variable\n",
    "* $m$ = regression slope / predictor coefficient\n",
    "* $b$ = y-intercept\n",
    "\n",
    "**Note**: It is common in the field of machine learning — which is itself a combination of several fields (math, statistics, computer science) — to use multiple terms interchangeably for a given concept. Note the above synonyms for the target and predictor variable terms — you'll encounter these synonyms across other readings and materials.\n",
    "### Sparse columns\n",
    "Dealing with sparse columns/features... \n",
    "- could just remove very sparse features\n",
    "- stratify train/test split based on all features -- not just the target variable\n",
    "- other options?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327c8a3-846d-4eda-899c-fb47e6599052",
   "metadata": {},
   "source": [
    "> Our above example model is able to explain roughly 27% of the variance in the test dataset. Is this a “good” value for R-squared?\n",
    "> \n",
    "> **Hint**: The answer to this question depends on your objective for the regression model. This relates back to the two tangentially related goals of *explaining* vs *predicting*, namely:\n",
    "> \n",
    "> 1. Are you interested in *explaining* the relationship between the predictor(s) and the response variable?\n",
    "> \n",
    "> OR\n",
    "> \n",
    "> 2. Are you interested in *predicting* the response variable?\n",
    "> \n",
    "> Depending on the objective, the answer to \"What is a good value for R-squared?\" will be different.\n",
    "> \n",
    "> > ## Solution\n",
    "> >\n",
    "> > #### Explaining the Relationship Between the Predictor(s) and the Response Variable\n",
    "> > If your main objective for your regression model is to explain the relationship(s) between the predictor(s) and the response variable, the R-squared is mostly irrelevant. A predictor variable that consistently relates to a change in the response variable is typically always interesting — regardless of the the effect size.\n",
    "> > \n",
    "> > #### Predicting the Response Variable\n",
    "> > If your main objective is to predict the value of the response variable accurately using the predictor variable, then R-squared is important. The value for R-squared can range from 0 to 1. A value of 0 indicates that the response variable cannot be explained by the predictor variable at all. A value of 1 indicates that the response variable can be perfectly explained without error by the predictor variable. In general, the larger the R-squared value, the more precisely the predictor variables are able to predict the value of the response variable. How high an R-squared value needs to be depends on how precise you need to be for your specific model's application. To find out what is considered a “good” R-squared value, you will need to explore what R-squared values are generally accepted in your particular field of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7b07d8-ad4b-4e61-ac2c-4af6de164400",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e4c195afecc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Condition2_PosA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Condition2_PosA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Condition2_PosA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Condition2_PosA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Condition2_PosA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train['Condition2_PosA'].max())\n",
    "print(X_test['Condition2_PosA'].max())\n",
    "X['Condition2_PosA'].describe()\n",
    "X['Condition2_PosA'].hist(bins=20)\n",
    "X['Condition2_PosA'].unique()\n",
    "# X['Condition2_PosA'].count()\n",
    "X['Condition2_PosA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5894a-da97-4b91-953d-4f40d51c85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "def normality_plot(X):\n",
    "    \"\"\"\n",
    "    1. Draw distribution plot with normal distribution fitted curve\n",
    "    2. Draw Quantile-Quantile plot \n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    sns.distplot(X, fit=norm, ax=axes[0])\n",
    "    axes[0].set_title('Distribution Plot')\n",
    "\n",
    "    axes[1] = stats.probplot((X), plot=plt)\n",
    "    plt.tight_layout()\n",
    "\n",
    "normality_plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a778c5c-1c92-4abb-9231-922c8b086391",
   "metadata": {},
   "source": [
    "#### Zscore target variable as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9187e3-a549-4a03-9275-dc428e634778",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_zscore = y_train.copy(deep=True) # dig into this\n",
    "y_train_zscore, target_mean, target_std = zscore_train(y_train_zscore.to_frame())\n",
    "# convert y's back to pandas series\n",
    "y_train_zscore=y_train_zscore.squeeze()\n",
    "y_train_zscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6db47f-b551-4f0c-a05e-b475588c2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_zscore = y_test.copy(deep=True) # dig into this\n",
    "y_test_zscore = zscore_test(y_test_zscore.to_frame(), target_mean, target_std)\n",
    "# convert y's back to pandas series\n",
    "y_test_zscore=y_test_zscore.squeeze()\n",
    "y_test_zscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea149d-513e-4d49-b13e-be823261af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll reference the target mean and std. later on. Since these objects are currently dictionaries, and we only have one key ('SalePrice'), we'll overwrite these dictionaries to store just their values\n",
    "target_mean = target_mean['SalePrice']\n",
    "target_std = target_std['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bac3b-6e65-42db-a180-20cd7c0b6e5b",
   "metadata": {},
   "source": [
    "#### Sanity check zscoring worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f3038-2a07-4d5b-8329-602b41fe51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - some precision error difference I believe brought on by np.mean and np.std\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "X_zscored = X_train.apply(zscore)\n",
    "y_zscored = pd.Series(zscore(y_train, 0))\n",
    "X_zscored.head()\n",
    "# y_zscored.head()\n",
    "# negligible difference\n",
    "plt.scatter(x=np.arange(0,len(y_train)),y=y_train_zscore,alpha=1)\n",
    "plt.scatter(x=np.arange(0,len(y_train)),y=y_zscored,alpha=1, s=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
