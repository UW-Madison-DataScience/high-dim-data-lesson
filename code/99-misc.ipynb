{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebdd0d-489e-40a1-acba-9b46d55f6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\n",
    "        \"theme\": \"black\",\n",
    "        \"transition\": None,\n",
    "        \"start_slideshow_at\": \"selected\",\n",
    "        \"enable_chalkboard\": True,\n",
    "        \"chalkboard\": {\n",
    "            \"color\": [\"rgb(225, 193, 7)\", \"rgb(30, 136, 229)\"]\n",
    "        },\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bfb29d-36ad-4f93-8093-3b560ace1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate the corresponding training scores for each alpha and fold\n",
    "from sklearn.linear_model import Lasso\n",
    "train_scores = []\n",
    "perc_sparse_vals = []\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=max_iter)\n",
    "    lasso.fit(X_train_z, y_train)\n",
    "    coefs = lasso.coef_\n",
    "    percent_sparse = np.mean(coefs == 0) * 100\n",
    "    pred = lasso.predict(X_train_z)\n",
    "    train_scores.append(np.mean((pred - y_train) ** 2))\n",
    "    perc_sparse_vals.append(percent_sparse)\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the training and validation scores\n",
    "ax1.plot(np.log10(alphas), train_scores, label='Train', marker='o')\n",
    "ax1.plot(np.log10(alphas), val_scores, label='Validation (CV)', marker='o')\n",
    "ax1.set_xlabel('log(alpha)')\n",
    "ax1.set_ylabel('Mean Squared Error')\n",
    "ax1.set_title('LassoCV Train/Validation Scores')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot percent sparsity\n",
    "ax2.plot(np.log10(alphas), perc_sparse_vals, label='Percent Sparsity', marker='o', color='orange')\n",
    "ax2.set_xlabel('log(alpha)')\n",
    "ax2.set_ylabel('Percent Sparsity')\n",
    "ax2.set_title('Percent Sparsity vs. alpha')\n",
    "ax2.grid(True)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig('..//fig//regression//regularize//alpha_cv_results.png', bbox_inches='tight', dpi=300, facecolor='white');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cdae0-c94a-4bbb-8873-777f9f44292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate the corresponding training scores for each alpha and fold\n",
    "from sklearn.linear_model import Lasso\n",
    "train_scores = []\n",
    "\n",
    "preds = []\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=max_iter)\n",
    "    lasso.fit(X_train_z, y_train)\n",
    "    pred = lasso.predict(X_train_z)\n",
    "    preds.append(pred)\n",
    "    train_scores.append(np.mean((pred - y_train) ** 2))\n",
    "\n",
    "# Plot the training and validation scores\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(np.log10(trained_model.alphas_), train_scores, label='Train', marker='o')\n",
    "plt.plot(np.log10(trained_model.alphas_), val_scores, label='Validation (CV)', marker='o')\n",
    "plt.xlabel('log(alpha)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('LassoCV Train/Validation Scores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('..//fig//regression//regularize//alpha_cv_results.png', bbox_inches='tight', dpi=300, facecolor='white');\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381a3ad-9376-4624-8b79-1a06d83d88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full-dim data (there's a helper fxn for this now)\n",
    "from sklearn.datasets import fetch_openml\n",
    "housing = fetch_openml(name=\"house_prices\", as_frame=True, parser='auto') #\n",
    "y=housing['target']\n",
    "X=housing['data']\n",
    "print('X.shape[1]', X.shape[1])\n",
    "import numpy as np\n",
    "y_log = np.log(y)\n",
    "\n",
    "from preprocessing import encode_predictors_housing_data\n",
    "X_encoded = encode_predictors_housing_data(X) # use one-hot encoding to encode categorical predictors\n",
    "print('X_encoded.shape[1]', X_encoded.shape[1]) \n",
    "\n",
    "from preprocessing import remove_bad_cols\n",
    "X_encoded_good = remove_bad_cols(X_encoded, 98) # remove cols with nans and cols that are 98% constant\n",
    "X_encoded_good.head()\n",
    "\n",
    "print(X_encoded_good.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3a7044-d3a0-40a0-92a4-da810819bc43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_linear_regression_with_kf\u001b[39m(features: pd\u001b[38;5;241m.\u001b[39mDataFrame, labels: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[0;32m     13\u001b[0m                                     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic regression model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m                                    ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m,\u001b[38;5;28mfloat\u001b[39m,\u001b[38;5;28mfloat\u001b[39m,\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    scale, split, and model data. Return model performance statistics, plot confusion matrix\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    feature: dataframe of feature columns to model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    return: recall mean, recall sd, precision mean, precision sd\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# set up splits/folds and array for stats.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_linear_regression_with_kf(features: pd.DataFrame, labels: pd.Series,\n",
    "                                    n_splits=5, title='logistic regression model'\n",
    "                                   ) -> Tuple[float,float,float,float]:\n",
    "    \"\"\"\n",
    "    scale, split, and model data. Return model performance statistics, plot confusion matrix\n",
    "    feature: dataframe of feature columns to model\n",
    "    labels: series of labels to model against\n",
    "    test_size: fraction of labels to use in test split\n",
    "    title: title for chart\n",
    "    return: recall mean, recall sd, precision mean, precision sd\n",
    "    \"\"\"\n",
    "    # set up splits/folds and array for stats.\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    r2s = np.zeros(n_splits)\n",
    "    rmses = np.zeros(n_splits)\n",
    "    train_rmses = np.zeros(n_splits)\n",
    "\n",
    "    # fit model for each split/fold\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X=features, y=labels)):\n",
    "        # split features data for dataframes\n",
    "        try:\n",
    "            X_train = features.iloc[train_idx]\n",
    "            y_train = labels.iloc[train_idx]\n",
    "            X_test = features.iloc[test_idx]\n",
    "            y_test = labels.iloc[test_idx]\n",
    "\n",
    "        # or split features data for ndarrays (pca transformed features)\n",
    "        except AttributeError:\n",
    "            X_train = features[train_idx]\n",
    "            y_train = labels.iloc[train_idx]\n",
    "            X_test = features[test_idx]\n",
    "            y_test = labels.iloc[test_idx]\n",
    "\n",
    "\n",
    "        # scale all features to training features\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # fit model, evaluate\n",
    "        regr = LinearRegression().fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        r2s[i] = r2_score(y_test, y_pred)\n",
    "        rmses[i] = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        y_pred_train = regr.predict(X_train)\n",
    "        train_rmses[i] = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "    r2_mean = r2s.mean()\n",
    "    r2_sd = r2s.std()\n",
    "    rmse_mean = rmses.mean()\n",
    "    rmse_sd = rmses.std()\n",
    "    train_rmse_mean = train_rmses.mean()\n",
    "    train_rmse_sd = train_rmses.std()\n",
    "\n",
    "    # plot y_true vs y_pred\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(y_test, y_pred, alpha=0.3)\n",
    "    ax.set_title(f'{title}\\n' \\\n",
    "                 'mean r2: {:.2f},\\n'\\\n",
    "                 'mean rmse {:.2f}'\n",
    "                 .format(r2_mean, rmse_mean)\n",
    "    )\n",
    "    ax.set_xlabel('True Value')\n",
    "    ax.set_ylabel('Predicted Value')\n",
    "    stats = (r2_mean, rmse_mean, r2_sd, rmse_sd)\n",
    "    train_test_errors = (rmse_mean, rmse_sd, train_rmse_mean, train_rmse_sd)\n",
    "    model_data_and_pred = (regr, X_train, y_train, X_test, y_test, y_pred)\n",
    "    fig_and_ax = (fig, ax)\n",
    "\n",
    "    return stats, train_test_errors, model_data_and_pred, fig_and_ax\n",
    "\n",
    "# set kfold splits\n",
    "n_splits = 3\n",
    "# keep all model stats in one dict\n",
    "all_stats = {}\n",
    "#r2_mean, rmse_mean, r2_sd, rmse_sd, regr, fig, ax = \n",
    "plt.ion()\n",
    "stats, train_test_errors, model_data_and_pred, fig_and_ax = run_linear_regression_with_kf(features=features, labels=target, n_splits=n_splits, title='all features')\n",
    "all_stats['all'] = stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50b2da-310a-4fdb-8b18-3e12c19f1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit train_linear_model to train ridge models as well\n",
    "def train_linear_model(X_train, y_train, model_type):\n",
    "    if model_type == \"unregularized\":\n",
    "        reg = LinearRegression().fit(X_train,y_train)\n",
    "    elif model_type == 'ridge':\n",
    "        reg = RidgeCV(alphas=[1e-3,1e-2,1e-1,1,10,100,1000], store_cv_values=True).fit(X_train,y_train)\n",
    "        print(reg.cv_values_.shape) # num_datapoints x num_alphas\n",
    "        print(np.mean(reg.cv_values_, axis=0))\n",
    "        print('alpha:', reg.alpha_)\n",
    "    elif model_type == 'lasso':\n",
    "        reg = LassoCV(random_state=0, alphas=[1e-3,1e-2,1e-1,1,10,100,1000], max_iter=100000, tol=1e-3).fit(X_train,y_train)\n",
    "        print('alpha:', reg.alpha_)\n",
    "        print('alphas:', reg.alphas_)\n",
    "    elif model_type == 'elastic':\n",
    "        reg = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1],alphas=[1e-5,1e-4,1e-3,1e-2,1e-1,1,10]).fit(X_train,y_train)\n",
    "        print('alpha:', reg.alpha_)\n",
    "        print('l1_ratio:', reg.l1_ratio_)\n",
    "    else:\n",
    "        raise ValueError('Unexpected model_type encountered; model_type = ' + model_type)\n",
    "\n",
    "    # print number of estimated model coefficients. Need to add one to account for y-intercept (not included in reg.coef_ call)\n",
    "    print('# model coefs = ' + str(len(reg.coef_)+1))\n",
    "\n",
    "    return reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faccac-81f4-4c50-9cc8-d0824e84fca3",
   "metadata": {},
   "source": [
    "- What is the model's train and test error? How does this compare to the unregularized model we fit using all predictor variables? How does this model compare to the best univariate model we fit?\n",
    "  - The ridge model does much better (i.e., in terms of Test RMSE) than the unregularized model that uses all predictor vars.\n",
    "  - Unregularized_all_predictors_testRMSE: 3562241001\n",
    "  - Unregularized_best_univariate_testRMSE: 48243\n",
    "  - Regularized_all_predictors_testRMSE: 39004\n",
    "\n",
    "- What alpha value was selected using RidgeCV? Is it a lower or higher value? What does this value tell you about the model?\n",
    "  - This model is highly regularized/penalized since it has a large alpha value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25098ee3-a07e-4813-b237-a1a183a4bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# # trained_model = RidgeCV(alphas=alphas, cv=10)\n",
    "# trained_model = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "\n",
    "# trained_model = trained_model.fit(X_train_z, y_train)\n",
    "# y_pred_train = trained_model.predict(X_train_z)\n",
    "# y_pred_test = trained_model.predict(X_test_z)\n",
    "\n",
    "# from regression_predict_sklearn import measure_model_err\n",
    "# error_df = measure_model_err(y=y, baseline_pred=y.mean(),\n",
    "#                               y_train=y_train, y_pred_train=y_pred_train,\n",
    "#                               y_test=y_test, y_pred_test=y_pred_test,\n",
    "#                               metric='RMSE', y_log_scaled=True)\n",
    "\n",
    "\n",
    "# error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badad932-15fb-4ea2-a707-b5152ef11350",
   "metadata": {},
   "outputs": [],
   "source": [
    "### try pca before LASSO\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "N_PC = min(80, X_train_z.shape[1])\n",
    "pca = PCA(n_components=N_PC)\n",
    "pca.fit(X_train_z)\n",
    "\n",
    "# Transform both training and test data using the same top 30 principal components\n",
    "X_train_pca = pca.transform(X_train_z)\n",
    "X_test_pca = pca.transform(X_test_z)\n",
    "\n",
    "# Create new DataFrames with the transformed values and the original column names\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f'PC{i+1}' for i in range(N_PC)])\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca, columns=[f'PC{i+1}' for i in range(N_PC)])\n",
    "\n",
    "# full-dim\n",
    "trained_model, error_df = fit_eval_model(y=y, baseline_pred=y.mean(),\n",
    "               X_train=X_train_pca_df, y_train=y_train,\n",
    "               X_test=X_test_pca_df, y_test=y_test, \n",
    "               predictors=X_train_pca_df.columns,\n",
    "               metric='RMSE',\n",
    "               y_log_scaled=True,\n",
    "               model_type='unregularized',\n",
    "               include_plots=True, plot_raw=True, verbose=True)\n",
    "\n",
    "# LASSO\n",
    "import numpy as np\n",
    "alphas = np.logspace(-5, 1, 500)\n",
    "trained_model, error_df = fit_eval_model(y=y, baseline_pred=y.mean(),\n",
    "                                         X_train=X_train_pca_df, y_train=y_train,\n",
    "                                         X_test=X_test_pca_df, y_test=y_test, \n",
    "                                         predictors=X_train_pca_df.columns,\n",
    "                                         metric='RMSE',\n",
    "                                         y_log_scaled=True,\n",
    "                                         model_type='LassoCV', alphas=alphas, cv=3, max_iter=100000,\n",
    "                                         include_plots=True, plot_raw=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8256d5-2bba-47d6-8607-006893f9481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### CODE_START\n",
    "# Extract target, `y` and predictors, `X`.\n",
    "y_log = np.log(housing['target']) \n",
    "predictors = ['LotArea', 'YearBuilt', 'YearRemodAdd', 'GarageArea', 'GarageCars', 'Neighborhood'] \n",
    "X=housing['data'][predictors]\n",
    "X.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "# Preprocess the data\n",
    "from preprocessing import encode_predictors_housing_data\n",
    "X_enc = encode_predictors_housing_data(X)\n",
    "X_enc.head()\n",
    "\n",
    "from preprocessing import remove_bad_cols\n",
    "X_good = remove_bad_cols(X_enc, 95) \n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "multicollinearity_test(X_good);\n",
    "X_better = X_good.drop(['GarageCars','YearBuilt'],axis = 1)\n",
    "multicollinearity_test(X_better);\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_better, y_log, test_size=0.33, random_state=0)\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from preprocessing import zscore\n",
    "X_train_z = zscore(df=X_train, train_means=X_train.mean(), train_stds=X_train.std())\n",
    "X_test_z = zscore(df=X_test, train_means=X_train.mean(), train_stds=X_train.std())\n",
    "X_train_z.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "# Add a constant column to the predictor variables dataframe\n",
    "X_train_z = sm.add_constant(X_train_z)\n",
    "print(X_train_z.head())\n",
    "# Add the constant to the test set as well so we can use the model to form predictions on the test set later\n",
    "X_test_z = sm.add_constant(X_test_z)\n",
    "print(X_test_z.head())\n",
    "# Fit the multivariate regression model\n",
    "model = sm.OLS(y_train, X_train_z)\n",
    "trained_model = model.fit()\n",
    "\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from regression_predict_sklearn import measure_model_err\n",
    "# to calculate residuals and R-squared for the test set, we'll need to get the model predictions first\n",
    "y_pred_train = trained_model.predict(X_train_z)\n",
    "y_pred_test = trained_model.predict(X_test_z)\n",
    "errors_df = measure_model_err(y, np.mean(y),\n",
    "                      y_train, y_pred_train,\n",
    "                      y_test, y_pred_test,\n",
    "                      'RMSE', y_log_scaled=True) \n",
    "\n",
    "errors_df.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "eval_regression_assumptions(trained_model=trained_model, X=X_train_z, y=y_train, \n",
    "                            y_pred=y_pred_train, y_log_scaled=True, plot_raw=False, threshold_p_value=.05);\n",
    "##### CODE_END\n",
    "\n",
    "#### EXERCISE_END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
