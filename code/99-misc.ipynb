{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebdd0d-489e-40a1-acba-9b46d55f6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\n",
    "        \"theme\": \"black\",\n",
    "        \"transition\": None,\n",
    "        \"start_slideshow_at\": \"selected\",\n",
    "        \"enable_chalkboard\": True,\n",
    "        \"chalkboard\": {\n",
    "            \"color\": [\"rgb(225, 193, 7)\", \"rgb(30, 136, 229)\"]\n",
    "        },\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50b2da-310a-4fdb-8b18-3e12c19f1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit train_linear_model to train ridge models as well\n",
    "def train_linear_model(X_train, y_train, model_type):\n",
    "    if model_type == \"unregularized\":\n",
    "        reg = LinearRegression().fit(X_train,y_train)\n",
    "    elif model_type == 'ridge':\n",
    "        reg = RidgeCV(alphas=[1e-3,1e-2,1e-1,1,10,100,1000], store_cv_values=True).fit(X_train,y_train)\n",
    "        print(reg.cv_values_.shape) # num_datapoints x num_alphas\n",
    "        print(np.mean(reg.cv_values_, axis=0))\n",
    "        print('alpha:', reg.alpha_)\n",
    "    elif model_type == 'lasso':\n",
    "        reg = LassoCV(random_state=0, alphas=[1e-3,1e-2,1e-1,1,10,100,1000], max_iter=100000, tol=1e-3).fit(X_train,y_train)\n",
    "        print('alpha:', reg.alpha_)\n",
    "        print('alphas:', reg.alphas_)\n",
    "    elif model_type == 'elastic':\n",
    "        reg = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1],alphas=[1e-5,1e-4,1e-3,1e-2,1e-1,1,10]).fit(X_train,y_train)\n",
    "        print('alpha:', reg.alpha_)\n",
    "        print('l1_ratio:', reg.l1_ratio_)\n",
    "    else:\n",
    "        raise ValueError('Unexpected model_type encountered; model_type = ' + model_type)\n",
    "\n",
    "    # print number of estimated model coefficients. Need to add one to account for y-intercept (not included in reg.coef_ call)\n",
    "    print('# model coefs = ' + str(len(reg.coef_)+1))\n",
    "\n",
    "    return reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faccac-81f4-4c50-9cc8-d0824e84fca3",
   "metadata": {},
   "source": [
    "- What is the model's train and test error? How does this compare to the unregularized model we fit using all predictor variables? How does this model compare to the best univariate model we fit?\n",
    "  - The ridge model does much better (i.e., in terms of Test RMSE) than the unregularized model that uses all predictor vars.\n",
    "  - Unregularized_all_predictors_testRMSE: 3562241001\n",
    "  - Unregularized_best_univariate_testRMSE: 48243\n",
    "  - Regularized_all_predictors_testRMSE: 39004\n",
    "\n",
    "- What alpha value was selected using RidgeCV? Is it a lower or higher value? What does this value tell you about the model?\n",
    "  - This model is highly regularized/penalized since it has a large alpha value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25098ee3-a07e-4813-b237-a1a183a4bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# # trained_model = RidgeCV(alphas=alphas, cv=10)\n",
    "# trained_model = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "\n",
    "# trained_model = trained_model.fit(X_train_z, y_train)\n",
    "# y_pred_train = trained_model.predict(X_train_z)\n",
    "# y_pred_test = trained_model.predict(X_test_z)\n",
    "\n",
    "# from regression_predict_sklearn import measure_model_err\n",
    "# error_df = measure_model_err(y=y, baseline_pred=y.mean(),\n",
    "#                               y_train=y_train, y_pred_train=y_pred_train,\n",
    "#                               y_test=y_test, y_pred_test=y_pred_test,\n",
    "#                               metric='RMSE', y_log_scaled=True)\n",
    "\n",
    "\n",
    "# error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badad932-15fb-4ea2-a707-b5152ef11350",
   "metadata": {},
   "outputs": [],
   "source": [
    "### try pca before LASSO\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "N_PC = min(80, X_train_z.shape[1])\n",
    "pca = PCA(n_components=N_PC)\n",
    "pca.fit(X_train_z)\n",
    "\n",
    "# Transform both training and test data using the same top 30 principal components\n",
    "X_train_pca = pca.transform(X_train_z)\n",
    "X_test_pca = pca.transform(X_test_z)\n",
    "\n",
    "# Create new DataFrames with the transformed values and the original column names\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f'PC{i+1}' for i in range(N_PC)])\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca, columns=[f'PC{i+1}' for i in range(N_PC)])\n",
    "\n",
    "# full-dim\n",
    "trained_model, error_df = fit_eval_model(y=y, baseline_pred=y.mean(),\n",
    "               X_train=X_train_pca_df, y_train=y_train,\n",
    "               X_test=X_test_pca_df, y_test=y_test, \n",
    "               predictors=X_train_pca_df.columns,\n",
    "               metric='RMSE',\n",
    "               y_log_scaled=True,\n",
    "               model_type='unregularized',\n",
    "               include_plots=True, plot_raw=True, verbose=True)\n",
    "\n",
    "# LASSO\n",
    "import numpy as np\n",
    "alphas = np.logspace(-5, 1, 500)\n",
    "trained_model, error_df = fit_eval_model(y=y, baseline_pred=y.mean(),\n",
    "                                         X_train=X_train_pca_df, y_train=y_train,\n",
    "                                         X_test=X_test_pca_df, y_test=y_test, \n",
    "                                         predictors=X_train_pca_df.columns,\n",
    "                                         metric='RMSE',\n",
    "                                         y_log_scaled=True,\n",
    "                                         model_type='LassoCV', alphas=alphas, cv=3, max_iter=100000,\n",
    "                                         include_plots=True, plot_raw=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8256d5-2bba-47d6-8607-006893f9481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### CODE_START\n",
    "# Extract target, `y` and predictors, `X`.\n",
    "y_log = np.log(housing['target']) \n",
    "predictors = ['LotArea', 'YearBuilt', 'YearRemodAdd', 'GarageArea', 'GarageCars', 'Neighborhood'] \n",
    "X=housing['data'][predictors]\n",
    "X.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "# Preprocess the data\n",
    "from preprocessing import encode_predictors_housing_data\n",
    "X_enc = encode_predictors_housing_data(X)\n",
    "X_enc.head()\n",
    "\n",
    "from preprocessing import remove_bad_cols\n",
    "X_good = remove_bad_cols(X_enc, 95) \n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "multicollinearity_test(X_good);\n",
    "X_better = X_good.drop(['GarageCars','YearBuilt'],axis = 1)\n",
    "multicollinearity_test(X_better);\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_better, y_log, test_size=0.33, random_state=0)\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from preprocessing import zscore\n",
    "X_train_z = zscore(df=X_train, train_means=X_train.mean(), train_stds=X_train.std())\n",
    "X_test_z = zscore(df=X_test, train_means=X_train.mean(), train_stds=X_train.std())\n",
    "X_train_z.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "# Add a constant column to the predictor variables dataframe\n",
    "X_train_z = sm.add_constant(X_train_z)\n",
    "print(X_train_z.head())\n",
    "# Add the constant to the test set as well so we can use the model to form predictions on the test set later\n",
    "X_test_z = sm.add_constant(X_test_z)\n",
    "print(X_test_z.head())\n",
    "# Fit the multivariate regression model\n",
    "model = sm.OLS(y_train, X_train_z)\n",
    "trained_model = model.fit()\n",
    "\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "from regression_predict_sklearn import measure_model_err\n",
    "# to calculate residuals and R-squared for the test set, we'll need to get the model predictions first\n",
    "y_pred_train = trained_model.predict(X_train_z)\n",
    "y_pred_test = trained_model.predict(X_test_z)\n",
    "errors_df = measure_model_err(y, np.mean(y),\n",
    "                      y_train, y_pred_train,\n",
    "                      y_test, y_pred_test,\n",
    "                      'RMSE', y_log_scaled=True) \n",
    "\n",
    "errors_df.head()\n",
    "##### CODE_END\n",
    "\n",
    "\n",
    "##### CODE_START\n",
    "eval_regression_assumptions(trained_model=trained_model, X=X_train_z, y=y_train, \n",
    "                            y_pred=y_pred_train, y_log_scaled=True, plot_raw=False, threshold_p_value=.05);\n",
    "##### CODE_END\n",
    "\n",
    "#### EXERCISE_END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
