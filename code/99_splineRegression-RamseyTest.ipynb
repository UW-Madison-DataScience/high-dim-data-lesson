{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968d5ebb-75ee-44dd-91f3-4f7a0ea537b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.nonparametric.api' has no attribute 'bspline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Loop over each predictor and create spline basis functions\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predictor \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:  \u001b[38;5;66;03m# Exclude the last column which is the target variable\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     splines \u001b[38;5;241m=\u001b[39m [sm\u001b[38;5;241m.\u001b[39mnonparametric\u001b[38;5;241m.\u001b[39mbspline(data[predictor], df\u001b[38;5;241m=\u001b[39mk, degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m knots]\n\u001b[0;32m     24\u001b[0m     splines_list\u001b[38;5;241m.\u001b[39mextend(splines)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Combine all sets of spline basis functions and add a constant for the intercept\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Loop over each predictor and create spline basis functions\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predictor \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:  \u001b[38;5;66;03m# Exclude the last column which is the target variable\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     splines \u001b[38;5;241m=\u001b[39m [sm\u001b[38;5;241m.\u001b[39mnonparametric\u001b[38;5;241m.\u001b[39mbspline(data[predictor], df\u001b[38;5;241m=\u001b[39mk, degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m knots]\n\u001b[0;32m     24\u001b[0m     splines_list\u001b[38;5;241m.\u001b[39mextend(splines)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Combine all sets of spline basis functions and add a constant for the intercept\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.nonparametric.api' has no attribute 'bspline'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Example data\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "X = np.random.rand(num_samples, 5)\n",
    "Y = 2 * X[:, 0] + 3 * np.sin(X[:, 1]) + 4 * np.log(X[:, 2]) + np.random.normal(0, 0.5, num_samples)\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame(X, columns=['X1', 'X2', 'X3', 'X4', 'X5'])\n",
    "data['Y'] = Y\n",
    "\n",
    "# Create B-spline basis functions for all predictors\n",
    "knots = [3, 5, 7]  # Adjust the number of knots as needed\n",
    "\n",
    "# Initialize an empty list to store spline basis functions for each predictor\n",
    "splines_list = []\n",
    "\n",
    "# Loop over each predictor and create spline basis functions\n",
    "for predictor in data.columns[:-1]:  # Exclude the last column which is the target variable\n",
    "    splines = [sm.nonparametric.bspline(data[predictor], df=k, degree=3) for k in knots]\n",
    "    splines_list.extend(splines)\n",
    "\n",
    "# Combine all sets of spline basis functions and add a constant for the intercept\n",
    "X_bspline = np.column_stack([spl.evaluated(data[predictor]) for spl in splines_list])\n",
    "X_bspline = sm.add_constant(X_bspline)\n",
    "\n",
    "# Fit the spline regression model\n",
    "model = sm.OLS(data['Y'], X_bspline).fit()\n",
    "\n",
    "# Perform hypothesis tests for individual coefficients\n",
    "print(\"Hypothesis tests for individual coefficients:\")\n",
    "for predictor in data.columns[:-1]:\n",
    "    print(f\"Hypothesis test for {predictor}:\")\n",
    "    print(model.t_test(predictor))\n",
    "\n",
    "# Perform F-test for joint significance of spline terms associated with each predictor\n",
    "print(\"F-tests for joint significance of spline terms:\")\n",
    "hypotheses_list = [f\"{predictor}={', '.join([f'{predictor}_{i}' for i in range(len(knots) + 3)])}\" for predictor in data.columns[:-1]]\n",
    "for i, predictor in enumerate(data.columns[:-1]):\n",
    "    print(f\"F-test for joint significance of spline terms associated with {predictor}:\")\n",
    "    print(model.f_test(hypotheses_list[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d9d49-bade-4668-9968-f4c089830c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "\n",
    "# Choose the number of knots for each feature\n",
    "num_knots = 3\n",
    "\n",
    "# Create the formula for spline regression using all columns except the dependent variable 'y'\n",
    "formula = \"SalePrice ~ \" + \" + \".join([f\"bs({col}, knots={num_knots})\" for col in X_train.columns if col != 'SalePrice'])\n",
    "\n",
    "# Create spline basis matrix using patsy\n",
    "spline_basis = dmatrix(formula, data=X_train)\n",
    "\n",
    "# Fit the spline regression model\n",
    "model = sm.OLS(y_train, spline_basis)\n",
    "result = model.fit()\n",
    "\n",
    "# Predict and plot the spline curve\n",
    "pred_data = {col: np.linspace(X_train[col].min(), X_train[col].max(), 100) for col in X_train.columns if col != 'y'}\n",
    "pred_df = pd.DataFrame(pred_data)\n",
    "spline_basis_pred = dmatrix(formula, data=pred_df)\n",
    "pred_y = result.predict(spline_basis_pred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# If the dataset has more than one independent variable, use a 3D plot\n",
    "if len(X_train.columns) > 2:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], X_train.iloc[:, 2], c='blue', label='Data')\n",
    "    ax.plot3D(pred_df.iloc[:, 0], pred_df.iloc[:, 1], pred_df.iloc[:, 2], color='red', label='Spline Regression')\n",
    "    ax.set_xlabel(df.columns[0])\n",
    "    ax.set_ylabel(df.columns[1])\n",
    "    ax.set_zlabel(df.columns[2])\n",
    "    ax.set_title('Spline Regression in 3D')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# If the dataset has two independent variables, use a 2D plot\n",
    "elif len(df.columns) == 2:\n",
    "    plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c='blue', label='Data')\n",
    "    plt.plot(pred_df.iloc[:, 0], pred_df.iloc[:, 1], color='red', label='Spline Regression')\n",
    "    plt.xlabel(df.columns[0])\n",
    "    plt.ylabel(df.columns[1])\n",
    "    plt.title('Spline Regression in 2D')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# If the dataset has only one independent variable, use a 1D plot\n",
    "else:\n",
    "    plt.scatter(df.iloc[:, 0], df['y'], c='blue', label='Data')\n",
    "    plt.plot(pred_df.iloc[:, 0], pred_y, color='red', label='Spline Regression')\n",
    "    plt.xlabel(df.columns[0])\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Spline Regression in 1D')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e8459-5e45-4c07-bc01-aa1988706fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_pred = trained_model.predict()\n",
    "\n",
    "# Perform the Ramsey RESET test with a quadratic specification\n",
    "X_quad = X_train.apply(np.square)\n",
    "X_quad_train = pd.concat([X_train, X_quad], axis=1)\n",
    "\n",
    "model_quad = sm.OLS(y_train, X_quad_train).fit()\n",
    "y_pred_quad = model_quad.predict()\n",
    "\n",
    "# Calculate the test statistic\n",
    "reset_test_stat = ((y_pred_quad - y_pred) ** 2).sum()\n",
    "\n",
    "# Perform F-test (assuming you have n observations and k predictors in total, including the intercept)\n",
    "n = len(X_train)\n",
    "k = X_train.shape[1] - 1  # Exclude the intercept\n",
    "df1 = 2  # Degrees of freedom for the numerator (difference in degrees of freedom between models)\n",
    "df2 = n - k - 1  # Degrees of freedom for the denominator\n",
    "\n",
    "F_stat = (reset_test_stat / df1) / ((y - y_pred_quad).var() / df2)\n",
    "\n",
    "# Perform the test by calculating the p-value (assuming you have scipy installed)\n",
    "from scipy.stats import f\n",
    "\n",
    "p_value = 1 - f.cdf(F_stat, df1, df2)\n",
    "\n",
    "print(\"Ramsey RESET test statistic:\", reset_test_stat)\n",
    "print(\"F-statistic:\", F_stat)\n",
    "print(\"p-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
